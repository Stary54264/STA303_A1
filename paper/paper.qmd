---
title: "Analyzing Influencing Factors of House Prices in Ames by Linear Regression"
author: "Jiadong Wang, Yanzun Jiang"
date: today
date-format: long
thanks: "Code and data supporting this paper is available at: <https://github.com/Stary54264/factors_affect_family_size_in_portugal>"
format: pdf
number-sections: true
toc: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
```

\newpage

# Introduction

Understanding the factors that influence family size is crucial for shaping social and economic policies. In many societies, particularly those with lower GDP per capita, family size is often linked to cultural and socioeconomic factors such as literacy levels and the age at which individuals marry. Portugal, despite being a European country, had a GDP per capita in 1980 comparable to that of Mexico, making it an interesting case study for fertility patterns. Prior research suggests that rural families tend to have more children than urban families, and birth rates may vary based on educational attainment and marital timing. According to this, our study aims to answer the following question: **"How do literacy and age of a marriage affect family size?"**.

Existing literature provides valuable insights into the relationship between family size, literacy, and marital age. Studies have shown that higher literacy levels among women are associated with reduced fertility rates due to increased awareness of family planning and career aspirations (BMC Public Health, 2022). Similarly, research on marriage timing suggests that early marriage is linked to larger family sizes due to prolonged reproductive periods (BMC Public Health, 2022; Open Public Health Journal, 2023). Comparative studies in China and India further indicate that shifting social norms and economic conditions play a crucial role in fertility decisions (Sage Journals, 2023). These findings highlight the importance of investigating how these variables interact within the Portuguese context.

To analyze this relationship, we will use Generalized Linear Models (GLMs) as they are well-suited for count data like family size. Specifically, Poisson regression or negative binomial regression will be considered based on the presence of overdispersion. Exploratory data analysis will be conducted to summarize key variables, followed by model selection techniques to identify the best-fitting statistical model. The final model will be interpreted in the context of existing literature to draw meaningful conclusions about the relationship between literacy, age at marriage, and family size in Portugal.

# Method

```{r}
#| include: false
#| warning: false
#| message: false

# Read Data
data <- read_csv(here::here("data", "cleaned_data.csv"))
```

The process begins by constructing the initial multiple linear regression model (Model 1) using selected predictors that are theoretically or empirically linked to the response variable. This model serves as a baseline for exploring the underlying relationships between predictors and the outcome. It provides a starting point to identify how well the chosen predictors explain the variance in the response variable.

```{r}
#| include: false
#| warning: false
#| message: false

# Fit Model 1
model1 <- lm(sale_price ~
               lot_area + overall_qual + year_built + roof_style +
               mas_vnr_area + total_bsmt_sf + central_air + garage_area +
               misc_val, data = data)

# Take out Fitted Values and Residuals
fit <- fitted(model1)
res <- resid(model1)
```

After Model 1 is developed, it is essential to validate its reliability by checking two conditions (conditional mean response and conditional mean predictor) and four assumptions (linearity, uncorrelated errors, constant variances, and normality). Graphical tools like residual plots, and Q-Q plots are applied. This diagnostic step identifies potential issues that may compromise the model's interpretability or predictive accuracy, guiding subsequent corrections.

If diagnostic checks reveal violations, variance-stabilizing transformation and Box-Cox transformation is performed. Variance stabilizing transformation is applied to variables with many zeros, which is to take their square root. Box-Cox transformation is applied to other variables, identifing an optimal power transformation or natural logarithmic transformation for the variables. Applying these transformations ensures that the model assumptions are more closely met, enhancing its validity. After the transformation, a refined model (Model 2) is constructed to account for the adjusted data distribution.

```{r}
#| include: false
#| warning: false
#| message: false

# Remove Categorical Predictors
box_cox_data <- data |>
  dplyr::select(-roof_style, -central_air, -mas_vnr_area, -misc_val) |>
  filter_all(all_vars(. != 0))

# Get Suitable Powers
summary(powerTransform(cbind(box_cox_data[, 1:6])))

# Do Box-Cox Transformation
new_data <- data |>
  dplyr::select(-roof_style, -central_air) |>
  mutate(sale_price = log(sale_price),
         lot_area = log(lot_area),
         overall_qual = overall_qual ^ 0.8,
         year_built = year_built ^ 34,
         mas_vnr_area = sqrt(mas_vnr_area),
         total_bsmt_sf = total_bsmt_sf ^ 0.33,
         garage_area = garage_area ^ 0.25,
         misc_val = sqrt(misc_val))

# Fit Model 2
model2 <- lm(sale_price ~
               lot_area + overall_qual + year_built + mas_vnr_area +
               total_bsmt_sf + garage_area + misc_val, data = new_data)
```

Model 2 is refined further by testing the significance of coefficients through hypothesis testing. This step examines whether the coefficients significantly contributes to the model or if it can be excluded without sacrificing explanatory power. A non-significant coefficient could simplify the model, while a significant one may provide valuable context for interpreting the predictors. Adjustments based on these tests lead to the construction of Model 3, a more refined version that aligns closely with theoretical considerations.

```{r}
#| include: false
#| warning: false
#| message: false

# Show Hypothesis Testing Result
summary(model2)
```

The all-subset selection process begins by systematically evaluating models with the same number of predictors. At this stage, the sole evaluation criterion is $R^2_{adj}$, which measures how well each model explains the variance in the response variable while accounting for the number of predictors. Models with higher $R^2_{adj}$ are preferred.

Once the best model within each size category is identified, these "best of size" models are compared to select the overall best-performing model. This step incorporates multiple criteria to balance model fit and complexity. $R^2_{adj}$ continues to be a key measure, but additional metrics like $AIC$, $AIC_c$, and $BIC$ are introduced. They all emphasize model fit while penalizing for complexity, with $AIC_c$ being useful for small sample sizes, and $BIC$ imposing a stricter penalty for model size. Models with lower criteria values are preferred. If two or more models perform similarly based on these metrics, $VIF$ is used. VIF quantifies multicollinearity, with lower values preferred.

By the end of this process, Model 4 is identified as the best subset of predictors. It balances explanatory power and simplicity.

```{r}
#| include: false
#| warning: false
#| message: false

# Do All-Subsets Selection
summary(regsubsets(sale_price ~ lot_area + overall_qual + year_built +
                     mas_vnr_area + total_bsmt_sf + garage_area + misc_val,
                   data = new_data, nbest = 1, nvmax = 7))

# Build the Models
model_A <- lm(sale_price ~ overall_qual, data = new_data)
model_B <- lm(sale_price ~ overall_qual + lot_area, data = new_data)
model_C <- lm(sale_price ~ overall_qual + lot_area + year_built,
              data = new_data)
model_D <- lm(sale_price ~ overall_qual + lot_area + year_built +
                total_bsmt_sf, data = new_data)
model_E <- lm(sale_price ~ overall_qual + lot_area + year_built +
                total_bsmt_sf + garage_area, data = new_data)
model_F <- lm(sale_price ~ overall_qual + lot_area + year_built +
                total_bsmt_sf + garage_area + mas_vnr_area, data = new_data)

# Get n and p
n <- nrow(new_data)
p_A <- length(coef(model_A)) - 1
p_B <- length(coef(model_B)) - 1
p_C <- length(coef(model_C)) - 1
p_D <- length(coef(model_D)) - 1
p_E <- length(coef(model_E)) - 1
p_F <- length(coef(model_F)) - 1
p2 <- length(coef(model2)) - 1

# Summarize the Criteria
summary_table <- 
  data.frame(Model = c("Model A", "Model B", "Model C", "Model D",
                       "Model E", "Model F","Model G"),
             R2 = c(summary(model_A)$adj.r.squared,
                    summary(model_B)$adj.r.squared,
                    summary(model_C)$adj.r.squared,
                    summary(model_D)$adj.r.squared,
                    summary(model_E)$adj.r.squared,
                    summary(model_F)$adj.r.squared,
                    summary(model2)$adj.r.squared),
             AIC = c(extractAIC(model_A, k = 2)[2],
                     extractAIC(model_B, k = 2)[2],
                     extractAIC(model_C, k = 2)[2],
                     extractAIC(model_D, k = 2)[2],
                     extractAIC(model_E, k = 2)[2],
                     extractAIC(model_F, k = 2)[2],
                     extractAIC(model2, k = 2)[2]),
             AIC_c = c(extractAIC(model_A, k = 2)[2] +
                         2 * (p_A + 2) * (p_A + 3) / (n - p_A - 1),
                       extractAIC(model_B, k = 2)[2] +
                         2 * (p_B + 2) * (p_B + 3) / (n - p_B - 1),
                       extractAIC(model_C, k = 2)[2] +
                         2 * (p_C + 2) * (p_C + 3) / (n - p_C - 1),
                       extractAIC(model_D, k = 2)[2] +
                         2 * (p_D + 2) * (p_D + 3) / (n - p_D - 1),
                       extractAIC(model_E, k = 2)[2] +
                         2 * (p_E + 2) * (p_E + 3) / (n - p_E - 1),
                       extractAIC(model_F, k = 2)[2] +
                         2 * (p_F + 2) * (p_F + 3) / (n - p_F - 1),
                       extractAIC(model2, k = 2)[2] +
                         2 * (p2 + 2) * (p2 + 3) / (n - p2 - 1)),
             BIC = c(extractAIC(model_A, k = log(n))[2],
                     extractAIC(model_B, k = log(n))[2],
                     extractAIC(model_C, k = log(n))[2],
                     extractAIC(model_D, k = log(n))[2],
                     extractAIC(model_E, k = log(n))[2],
                     extractAIC(model_F, k = log(n))[2],
                     extractAIC(model2, k = log(n))[2]),
             VIF = c(0, max(vif(model_B)), max(vif(model_C)),
                     max(vif(model_D)), max(vif(model_E)),
                     max(vif(model_F)), max(vif(model2))))

# Round the Values
summary_table <- summary_table |>
  mutate(across(where(is.numeric), ~ round(., 2)))
```

To refine Model 2, automated selection tools could also employed. The method we used is stepwise selection, which assess predictor subsets, streamlining the selection process. It enhance efficiency while maintaining rigor in identifying the most suitable predictors. Model 5, is the culmination of this process, balancing explanatory power and simplicity.

```{r}
#| include: false
#| warning: false
#| message: false

# Do Stepwise Selection
stepAIC(lm(sale_price ~ ., data = new_data, direction = "both", k = 2))
```

# Results

In this study, we followed a systematic process to build and evaluate multiple regression models. Models 1 through 5 were developed and assessed based on several performance criteria. The models were constructed step by step, starting from a full model and progressing through various techniques to improve model performance. Below, we describe the key steps for building Models 1 through 5 and the results for each model.

## Model 1

Model 1 was constructed by fitting a simple linear regression model using the initially selected predictors. At this stage, the goal was to build a baseline model to examine the relationship between the predictors and the response variable. This model was used to assess the overall fit, and the results from this initial model informed subsequent steps. This model allowed us to identify areas where assumptions may have been violated, and highlighted the need for transformations in subsequent steps. Overall, Model 1 provided the groundwork for more advanced models that followed, which involved further diagnostic checks and adjustments.

## Model 2

By checking the conditions (conditional mean response and conditional mean predictors), the validity of the results of residual plots would be ensured. After checking the assumptions (linearity, uncorrelated errors, constant variances, and normality) in Model 1 using residual plots and Q-Q plots, we observed that some violations exists. Plots are available in @sec-assumptions.

To stabilize the variance and improve model fit, we applied variance-stabilizing transformation with variable with zeros, and Box-Cox transformation to other variables. This transformation improved the adherence to the assumptions.

After applying the transformations, we fit another model, Model 2, and checked the assumptions again. The transformed model performed better in terms of the assumptions compared to Model 1, suggesting that the the transformations have a positive effect.

## Model 3

Model 3 was built by performing hypothesis testing for each coefficient in Model 2. The goal was to evaluate the significance of each predictor and determine whether they contributed meaningfully to explaining the response variable. We set $\alpha=0.05$, and used the function `summary()` in R to get a summary table. In the p-value column in the table, we found out that all predictors have a p-value that is smaller than 0.05, meaning all coefficients are significant.

This process led to a refined set of predictors, where only those with statistically significant relationships to the response variable remained in the model. However, since all coefficients are significant, Model 3 is the same model as Model 2.

## Model 4

Model 4 was constructed using an all-subset regression approach, where the models with same number of predictors are compared using $R^2_{adj}$. Then, the best of bests is selected using $R^2_{adj}$, $AIC$, $AIC_c$, and $BIC$. thses values are listed in @tbl-subset. This technique allowed us to compare multiple models and select the one that provided the best trade-off between fit and complexity.

```{r, fig.pos="H"}
#| label: tbl-subset
#| tbl-cap: Criteria for Model of Each Size
#| echo: false
#| warning: false
#| message: false

# Show the Table
kable(summary_table,
      col.names = c("Model", "R^2_{adj}", "AIC",
                    "AIC_c", "BIC", "VIF_{max}"))
```

The results showed that Model F and Model G has similar $R^2_{adj}$. However, Model G has smaller $AIC$ and $AIC_c$, while Model F has smaller $BIC$. Since $BIC$ has severe penalty on more predictors, we choose Model G to be Model 4. Additionally, the maximum $VIF$ values were all below the threshold of 5, suggesting that multicollinearity was not a concern in the chosen model. The all-subset regression approach led to a model that balanced complexity and predictive accuracy effectively. Since Model 4 is also a full model, it is the same model as Model 2.

## Model 5

Finally, Model 5 was built using an automated selection tool, specifically a stepwise selection procedure, which included both forward and backward selection. The tool was set to evaluate models based on $AIC$, and we start with a full model. This automated process iteratively added or removed predictors to find the best model.

The stepwise selection only take one step to find the best model - the full model (Model 5), since deleting any predictor would result in a larger $AIC$. The automated selection procedure confirmed that the full model was indeed optimal for explaining the variance in the response variable.

## Conclusion

In summary, Models 3, 4, and 5 are the full model. While each model incorporated slightly different techniques and adjustments, none of the models significantly outperformed the others. So, we are confident to conclude that the optimal model to answer the research question is just the full model with variables transformed.

# Conclusion and Limitations

## Conclusion

This study aimed to investigate the relationship between the predictors and the response variable using a series of linear models. The results is that all numerical predictors affects house prices. Based on the analysis of the final model, the linear relationship between the predictors and the response variable was confirmed, and the results support the hypothesis.

The final model we choose is Model 2 (Model 3, 4, and 5). Its formula is listed below. The result could be interpreted in this way: "For a one-unit increase in `ln(lot_area)`, we expected `ln(sale_price)` to increase by 0.187". The findings are not surprising, and they align with the literatures.

\begin{align}
\begin{split}
ln(Y)=&8.57+0.187 \times ln(X_1)+0.280 \times X_2^{0.8}+\\
&1.47 \times 10^{-113} \times X_3^{34}+3.35 \times 10^{-3} \times X_4^{0.5}+0.0229 \times X_5^{0.33}+\\
&0.0348 \times X_6^{0.25}+(-1.03 \times 10^{-3}) \times X_7^{0.5}+\epsilon
\end{split}
\end{align}

$Y$: `sale_price`

$X_1$: `lot_area`

$X_2$: `overall_qual`

$X_3$: `year_built`

$X_4$: `mas_vnr_area`

$X_5$: `total_bsmt_sf`

$X_6$: `garage_area`

$X_7$: `misc_val`

## Limitation

Despite the insights gained through this process, the study has several limitations. One significant limitation is the assumption of linearity inherent in multiple linear regression. This assumption may not hold in all cases, particularly when the true relationship between the variables is non-linear. In such cases, linear regression models may be less accurate, and alternative techniques such as non-linear regression or machine learning methods may be more appropriate. Additionally, the models evaluated in this paper were limited to a specific set of predictors and may not fully account for other potentially relevant variables. The inclusion of more variables, or the use of more complex models such as interaction terms, could improve the predictive power of the model.

Another limitation is that in this study, we did not perform a train-test split, which means the models were evaluated on the entire dataset rather than being validated on unseen data. This approach prioritizes understanding the relationships between variables and the underlying structure of the data, rather than focusing on predictive accuracy. While this method provides valuable insights into the model's fit and the significance of various predictors, it does not allow for an assessment of how well the model would generalize to new, unseen data. As a result, the primary objective here was to explore and interpret the model, rather than make predictions.

\newpage

\appendix

# Appendix {-}

# Graphs of Conditions and Assumptions Checking {#sec-assumptions}

## Conditions

```{r, fig.pos="H"}
#| label: fig-fit-resp
#| fig-cap: Responses vs. Fitted Values
#| echo: false
#| warning: false
#| message: false

# Plot responses against fitted values
plot(x = fit, y = data$sale_price,
     xlab = "Fitted Values",
     ylab = "Responses")

abline(a = 0, b = 1, lty = 2)
```

We can see from @fig-fit-resp that the points scattered along the diagonal, so conditional mean predictor is fulfilled.

```{r, fig.pos="H"}
#| label: fig-pair
#| fig-cap: Pairwise Scatterplots of Predictors
#| echo: false
#| warning: false
#| message: false

# Convert variables to factors
data$central_air <- as.factor(data$central_air)
data$roof_style <- as.factor(data$roof_style)

# Plot predictors against each other
pairs(data[, 2:9])
```

We cannot see any non-linear patterns in @fig-pair, so conditional mean response is fulfilled.

Since both conditions are satisfied, we are confident that the result of the residual plots would be valid.

## Assumptions

```{r, fig.pos="H", fig.height=6, fig.width=8}
#| label: fig-res-1
#| fig-cap: Residuals vs. Observation - I
#| echo: false
#| warning: false
#| message: false

# Plot Residuals Against `lot_area`
res1 <- ggplot(data, aes(x = lot_area, y = res)) +
  geom_point() +
  xlab("`lot_area`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `overall_qual`
res2 <- ggplot(data, aes(x = overall_qual, y = res)) +
  geom_point() +
  xlab("`overall_qual`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `year_built`
res3 <- ggplot(data, aes(x = year_built, y = res)) +
  geom_point() +
  xlab("`year_built`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `mas_vnr_area`
res4 <- ggplot(data, aes(x = mas_vnr_area, y = res)) +
  geom_point() +
  xlab("`mas_vnr_area`") +
  ylab("Residuals") +
  theme_minimal()

# Show 4 Residual Plots Together
res1 + res2 + res3 + res4
```

```{r, fig.pos="H", fig.height=6, fig.width=8}
#| label: fig-res-2
#| fig-cap: Residuals vs. Observation - II
#| echo: false
#| warning: false
#| message: false

# Plot Residuals Against `total_bsmt_sf`
res5 <- ggplot(data, aes(x = total_bsmt_sf, y = res)) +
  geom_point() +
  xlab("`total_bsmt_sf`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `garage_area`
res6 <- ggplot(data, aes(x = garage_area, y = res)) +
  geom_point() +
  xlab("`garage_area`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `misc_val`
res7 <- ggplot(data, aes(x = misc_val, y = res)) +
  geom_point() +
  xlab("`misc_val`") +
  ylab("Residuals") +
  theme_minimal()

# Show 3 Residual Plots Together
res5 + res6 + res7
```

```{r, fig.pos="H", fig.height=6, fig.width=8}
#| label: fig-res-3
#| fig-cap: Residuals vs. Observation - III
#| echo: false
#| warning: false
#| message: false

# Plot Residuals Against `roof_style`
res8 <- ggplot(data, aes(x = roof_style, y = res)) +
  geom_boxplot() +
  xlab("`roof_style`") +
  ylab("Residuals") +
  theme_minimal()

# Plot Residuals Against `central_air`
res9 <- ggplot(data, aes(x = central_air, y = res)) +
  geom_boxplot() +
  xlab("`central_air`") +
  ylab("Residuals") +
  theme_minimal()

# Show 2 Boxplots Together
res8 + res9
```

We can see some violations of constant variance in @fig-res-1, @fig-res-2, and @fig-res-3 for variables except `year_built`, since the spread of the points becomes wider with increasing $x$. So, a transformation is needed for them.

```{r, fig.pos="H", fig.height=6, fig.width=8}
#| label: fig-qq-1
#| fig-cap: Q-Q Plot - I
#| echo: false
#| warning: false
#| message: false

# Show 4 Q-Q Plots Together
par(mfrow=c(2,2))

# Plot the Q-Q Plot for `sale_price`
qqnorm(data$sale_price, main = "`sale_price`")
qqline(data$sale_price, col = "red")

# Plot the Q-Q Plot for `lot_area`
qqnorm(data$lot_area, main = "`lot_area`")
qqline(data$lot_area, col = "red")

# Plot the Q-Q Plot for `overall_qual`
qqnorm(data$overall_qual, main = "`overall_qual`")
qqline(data$overall_qual, col = "red")

# Plot the Q-Q Plot for `year_built`
qqnorm(data$year_built, main = "`year_built`")
qqline(data$year_built, col = "red")
```

```{r, fig.pos="H", fig.height=6, fig.width=8}
#| label: fig-qq-2
#| fig-cap: Q-Q Plot - II
#| echo: false
#| warning: false
#| message: false

# Show 4 Q-Q Plots Together
par(mfrow=c(2,2))

# Plot the Q-Q Plot for `mas_vnr_area`
qqnorm(data$mas_vnr_area, main = "`mas_vnr_area`")
qqline(data$mas_vnr_area, col = "red")

# Plot the Q-Q Plot for `total_bsmt_sf`
qqnorm(data$total_bsmt_sf, main = "`total_bsmt_sf`")
qqline(data$total_bsmt_sf, col = "red")

# Plot the Q-Q Plot for `garage_area`
qqnorm(data$garage_area, main = "`garage_area`")
qqline(data$garage_area, col = "red")

# Plot the Q-Q Plot for `misc_val`
qqnorm(data$misc_val, main = "`misc_val`")
qqline(data$misc_val, col = "red")
```

We can see some violations of normality in @fig-qq-1 and @fig-qq-2 for variables except `total_bsmt_sf` and `garage_area`, since the points does not scattered along the diagonal. So, a transformation is needed for them.

# Ethics Discussion

Our data is collected from Ames City Assessor's Office (@ames), then we cleaned the data to only keep some necessary key factors that is highly relavant to house prices. Raw and processed versions of the data from De Cock is published on Journal of Statistics Education in 2011. The cleaned data we are using includes some detailed information about housing characteristics, but does not contain personal identifiers.

The Ames housing dataset has been used widely, especially in the context of academic projects and machine learning competitions. It is often considered a modern alternative to the Boston Housing dataset. The dataset is well-vetted and trusted by the data science community for its comprehensiveness and relevance.

Automated selection method is efficient, consistent, and able to handle large-scale data. We choose automated selection method in Model 5 of our analysis to avoid subjective judgment and negligence. While automated tools can enhance productivity, they should not replace human judgment. By addressing these ethical considerations, we can leverage the benefits of automated selection tools while maintaining the integrity and fairness during our research practices.

# Editing Demonstration

## Original Version of Introduction

The primary research question we aim to answer is: What are the key factors that significantly influence house prices in Ames from 2006 to 2010? Sale price of the house is the response variable. Predictor variables include area, overall quality index, year of construction, house facilities, and value of miscellaneous feature. By identifying and analyzing the factors that significantly influence house prices, our research can offer practical recommendations for various stakeholders, ultimately contributing to a more efficient and transparent real estate market in Ames. Similar analysis can be done to other cities to improve economic insights and investment decisions.

We will test whether there is a statistically significant linear relationship between certain property characteristics (predictors) and the sale price of houses (response) using linear regression. We use residual plots and a Q-Q plot to check the assumption. Linear regression provides coefficients that quantify the relationship between each predictor and the response variable, making it easier to interpret the impact of each factor alone on house prices. Our primary goal is to understand the impact of each predictor on house prices, so the focus should be on interpretability instead of precision.

We found several peer-reviewed articles that focus on similar problems with this paper. "Influencing Factors Analysis of House Prices Based on Multiple Linear Regression" concludes that housing prices are negatively correlated with completion costs, land acquisition prices, residents’ disposable income, and population density (@influencing). This article provides some characteristics other than what we use that can also influence house price in national scope.

In "Dynamic Relationships Between Commodity Prices and Local Housing Market", this research examines the significant nonlinear relationship between agricultural commodity prices and the local housing market (@dynamic). The research "Non-Linear Relationships Between House Size and Price" clarifies the nonlinear relationships between housing size and price (@size). These two researches explain another aspect, a non-linear relationship, between house price and other factors, providing more comprehensive information about house market for decision making of the developers, home purchasers, real estate appraisers, and the governments.

## Edited Version of Introduction

The research question we aim to answer is: what are the factors that influence house prices in Ames from 2006 to 2010? We would set up a linear regression model to answer the research question with house prices as response. Predictors include area, quality, year of construction, facilities, etc. Our research can offer practical recommendations for various stakeholders, contributing to a more efficient and transparent real estate market in Ames. Similar analysis can be done to other cities to improve economic insights and investment decisions.

By setting up the model, we can identify the factors that influence house prices. Linear regression allows us to quantify the relationship between predictors and responses, making it easier to interpret the impact of each factor alone on house prices. Our primary goal is understanding the factors that influence historical house prices, so our focus would be on description rather than prediction.

We found several peer-reviewed articles that focus on similar problems with this paper. "Influencing Factors Analysis of House Prices Based on Multiple Linear Regression" concludes that housing prices are negatively correlated with completion costs, land acquisition prices, residents’ disposable income, and population density (@influencing). This article provides some alternative characteristics that also influence house price in national scope.

In "Dynamic Relationships Between Commodity Prices and Local Housing Market", the researchers examines the significant nonlinear relationship between agricultural commodity prices and the house prices (@dynamic). Another research, "Non-Linear Relationships Between House Size and Price", clarifies the non-linear relationship between house size and price (@size). These two researches explain the non-linear relationship between house price and other factors, providing more insights into ways that factors might affect house prices.

## Comments on the Process

Editor: Siyuan Lu

We choose to edit the introduction by simplicity, since our original introduction contains some clutters. We can improve the introduction to make it clearer and shorter.

It is easy to delete some complex sentences when read the introduction with the editing techniques. However, breaking and modifying sentences in clearer and fewer words is quite challenging.

# Contributions

Group contribution is available at <https://github.com/Stary54264/Housing-in-Ames/graphs/contributors>. Below is a more specific version of group contribution.

- Yanzun Jiang: Organized discussions and meetings; assigned tasks to group members; set up Github workspace for collaborating; built the model; checked conditions and assumptions; refined the model by transformation, hypothesis testing, all-subset selection, and automated selection tools; made the reference list; revised group member's work; combined group member's work together.

- Siyuan Lu: Set research question; searched and read peer-reviewed articles; introduced the project; checked data ethics; edited introduction.

- Yi Tang: Designed the poster.

# R Packages and Dataset

R [@r] was used to conduct this research. Packages used include `tidyverse` [@tidyverse], `knitr` [@knitr], `patchwork` [@patchwork], `car` [@car], `leaps` [@leaps], and `MASS` [@MASS]. the dataset used is Ames Housing dataset [@ameshousing] from @ames.

\newpage

# References
